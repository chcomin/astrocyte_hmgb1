{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88c51573",
   "metadata": {},
   "source": [
    "### Segmentation of the blood vessels and calculation of density and banching point density\n",
    "\n",
    "*Step (b) of the block diagram in the methods section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0d30c6",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initial imports and device setting\n",
    "\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "from torchtrainer.imagedataset import ImageSegmentationDataset\n",
    "from torchtrainer import img_util\n",
    "from torchtrainer import transforms\n",
    "from torchtrainer.models.resunet import ResUNet\n",
    "from torchtrainer.learner import Learner\n",
    "from torchtrainer import perf_funcs\n",
    "\n",
    "import pyvane\n",
    "from pyvane import pipeline, image\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f79b3b6c",
   "metadata": {},
   "source": [
    "### CNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e41442cb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def name_to_label_map(img_filename):  \n",
    "    \n",
    "    return img_filename.replace('.tiff', '.png')\n",
    "\n",
    "def get_train_val_files(img_dir, val_split, seed=None):\n",
    "    \n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    files = os.listdir(img_dir)\n",
    "    val_files = []\n",
    "    train_files = []\n",
    "    \n",
    "    num_val_files = int(len(files)*val_split)\n",
    "    val_files = random.sample(files, num_val_files)\n",
    "    train_files = filter(lambda x: x not in val_files, files)\n",
    "\n",
    "    return train_files, val_files\n",
    "\n",
    "root_dir = Path('vessels')\n",
    "img_dir = root_dir/'images'     # Original images\n",
    "label_dir = root_dir/'labels'   # Labels\n",
    "\n",
    "img_shape = (1104, 1376)\n",
    "patch_shape = (256, 256)\n",
    "valid_shape = (768, 768)\n",
    "bs = 10                         # Batch size\n",
    "lr = 0.01                       # Learning rate\n",
    "epochs = 10\n",
    "\n",
    "# Image augmentations\n",
    "imgaug_seq = iaa.Sequential([\n",
    "    iaa.CropToFixedSize(width=patch_shape[1], height=patch_shape[0]),\n",
    "    iaa.GaussianBlur(sigma=[1, 2]),\n",
    "    iaa.OneOf([\n",
    "        iaa.GammaContrast(gamma=(0.5, 1.5)),\n",
    "        iaa.pillike.EnhanceBrightness(factor=(0.1, 3.)),\n",
    "        iaa.pillike.EnhanceContrast(factor=(0.2, 3.)),\n",
    "        iaa.Add(value=(-20, 30))\n",
    "    ]),\n",
    "    iaa.AdditiveGaussianNoise(loc=0, scale=(0, 20)),\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Flipud(0.5),\n",
    "    iaa.Crop(px=(0, 20)),\n",
    "    iaa.CLAHE(clip_limit=6, tile_grid_size_px=12)\n",
    "])\n",
    "imgaug_seq = transforms.translate_imagaug_seq(imgaug_seq)\n",
    "train_transforms = [transforms.TransfToImgaug(), imgaug_seq, transforms.TransfToTensor(), \n",
    "                    transforms.TransfWhitten(67.576, 37.556)]   # Statistics calculated over the whole dataset\n",
    "\n",
    "imgaug_seq = iaa.Sequential([\n",
    "    iaa.CenterCropToFixedSize(width=valid_shape[1], height=valid_shape[0]),\n",
    "    iaa.CLAHE(clip_limit=6, tile_grid_size_px=12)\n",
    "])    \n",
    "imgaug_seq = transforms.translate_imagaug_seq(imgaug_seq)\n",
    "valid_transforms = [transforms.TransfToImgaug(), imgaug_seq, transforms.TransfToTensor(), \n",
    "                    transforms.TransfWhitten(67.576, 37.556)]\n",
    "\n",
    "img_opener_partial = partial(img_util.pil_img_opener, channel=None)\n",
    "label_opener_partial = partial(img_util.pil_img_opener, is_label=True)\n",
    "\n",
    "# Create ImageDataset instance\n",
    "dataset = ImageSegmentationDataset(img_dir, label_dir, name_to_label_map=name_to_label_map,\n",
    "                            img_opener=img_opener_partial, label_opener=label_opener_partial,\n",
    "                            cache_size=10*10**9)\n",
    "\n",
    "train_ds, valid_ds = dataset.split_train_val(0.2, seed=10)\n",
    "train_ds.set_transforms(train_transforms)\n",
    "valid_ds.set_transforms(valid_transforms)\n",
    "train_dl = train_ds.dataloader(batch_size=bs, shuffle=True)\n",
    "valid_dl = valid_ds.dataloader(batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2136b36b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "loss_func = perf_funcs.DiceLossRaw()\n",
    "\n",
    "model = ResUNet(num_channels=1, num_classes=2) \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, epochs=epochs, \n",
    "                                                steps_per_epoch=len(train_dl), pct_start=0.1)\n",
    "\n",
    "learner = Learner(model, loss_func, optimizer, train_dl, valid_dl, scheduler, \n",
    "                       perf_funcs=perf_funcs.build_segmentation_accuracy_dict(), checkpoint_file='learner_vessel.tar',\n",
    "                       main_perf_func='iou', scheduler_step_epoch=False)\n",
    "\n",
    "learner.fit(epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b8d0804",
   "metadata": {},
   "source": [
    "### Medial lines and graph creation\n",
    "\n",
    "The code below creates a graph of the blood vessels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe66d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some definitions\n",
    "\n",
    "def load_roi(file):\n",
    "    '''P0 tissue does not fill the whole sample. We need to consider only\n",
    "    regions with tissue.'''\n",
    "    \n",
    "    if 'P0' in str(file):\n",
    "        file_roi = str(file).replace('CD31(vessels)', 'masks').replace('CD31.tif', 'GFP.png')\n",
    "        img_roi = plt.imread(file_roi).astype(np.uint8)\n",
    "        return img_roi\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "root = 'Astrocytes/'\n",
    "\n",
    "params = {\n",
    "    # Pipeline params\n",
    "    'save_steps': ('skeletonization', 'network'), \n",
    "    'roi_process': None,\n",
    "    'roi_analysis': load_roi,\n",
    "    # File params\n",
    "    'batch_name':    '2D analysis astrocytes',\n",
    "    'input_path':     root+'/CD31(vessels)/',\n",
    "    'output_path':    root+'/pipeline_vessels/',\n",
    "    'name_filter': None,\n",
    "    'channel_to_use': None,\n",
    "    # Skeletonization params\n",
    "    'num_threads': 7,\n",
    "    # Graph params\n",
    "    'length_threshold': 9,    # Graph pruning length in pixels.\n",
    "    # Measurement params\n",
    "    'tortuosity_scale': 40,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db28be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNSegmentation(pyvane.pipeline.BaseProcessor):\n",
    "    '''Fake segmenter. It just reads the files segmented using the CNN model above.'''\n",
    "    \n",
    "    def __init__(self, model, checkpoint_file):\n",
    "        pass\n",
    "        \n",
    "    def apply(self, img, file):\n",
    "\n",
    "        file_binary = file.replace('.tif', '.png')\n",
    "        img_final = np.array(Image.open(file_binary))\n",
    "        img_final = img_final//255\n",
    "        \n",
    "        return image.Image(img_final.astype(np.uint8), img.path, pix_size=img.pix_size)\n",
    "        \n",
    "img_reader = partial(pipeline.read_and_adjust_img, channel=params['channel_to_use'], roi=params['roi_process'])\n",
    "model = ResUNet(num_channels=1, num_classes=2)         \n",
    "checkpoint_file = 'learner_vessel.tar'\n",
    "segmenter = CNNSegmentation(model, checkpoint_file)\n",
    "skeleton_builder = pipeline.DefaultSkeletonBuilder(\n",
    "            num_threads=params['num_threads']\n",
    ")\n",
    "network_builder = pipeline.DefaultNetworkBuilder(\n",
    "            length_threshold = params['length_threshold']\n",
    ")\n",
    "analyzer = pipeline.DefaultAnalyzer(\n",
    "            tortuosity_scale=params['tortuosity_scale']\n",
    ")\n",
    "analyzer.load_roi = params['roi_analysis']\n",
    "\n",
    "pipe = pipeline.BasePipeline(params['input_path'], img_reader, output_path=params['output_path'],\n",
    "                             batch_name=params['batch_name'], name_filter=params['name_filter'])\n",
    "pipe.set_processors(segmenter, skeleton_builder, network_builder, analyzer)\n",
    "\n",
    "res = pipe.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
